<!DOCTYPE html>
<html>
<head>
<title>Technical_Design_RAG_Pipeline.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="technical-and-design-document-rag-pipeline-retrieval-augmented-generation-system">Technical and Design Document: RAG Pipeline Retrieval-Augmented Generation System</h1>
<h2 id="abstract">Abstract</h2>
<p>RAG Pipeline is a modular, production-ready Retrieval-Augmented Generation (RAG) system for document-based question answering. It integrates ChromaDB for vector search, LangChain for orchestration, and GROQ for large language model (LLM) inference. The system supports both a modern Streamlit web interface and a comprehensive command-line interface (CLI), enabling flexible, scalable, and secure document ingestion, retrieval, and conversational AI workflows.</p>
<h2 id="1-introduction-and-motivation">1. Introduction and Motivation</h2>
<p>The exponential growth of unstructured data has created a need for systems that can efficiently retrieve and synthesize information from large document collections. RAG Pipeline addresses this by combining state-of-the-art vector search with LLMs, providing both technical and non-technical users with powerful tools for document-based Q&amp;A, analytics, and knowledge management.</p>
<h2 id="2-system-architecture">2. System Architecture</h2>
<h3 id="21-high-level-overview">2.1 High-Level Overview</h3>
<ul>
<li><strong>Ingestion Layer</strong>: Handles document loading, parsing, and chunking.</li>
<li><strong>Vector Store</strong>: Uses ChromaDB for efficient similarity search over document embeddings.</li>
<li><strong>LLM Layer</strong>: Integrates with GROQ API for text generation and answer synthesis.</li>
<li><strong>Interface Layer</strong>: Dual interface—Streamlit web UI and CLI—for all operations.</li>
<li><strong>Configuration &amp; Logging</strong>: YAML-based config, .env for secrets, and timestamped logs.</li>
</ul>
<h3 id="22-component-diagram">2.2 Component Diagram</h3>
<pre><code class="language-mermaid"><div class="mermaid">flowchart TD
    User(["User (Web/CLI)"])
    UI(["Interface Layer\n(Streamlit/CLI)"])
    Ingest(["Ingestion Layer\n(Document Loader)"])
    VectorDB(["Vector Store\n(ChromaDB)"])
    LLM(["LLM Layer\n(GROQ)"])
    Logs(["Logs/Stats"])

    User --> UI
    UI --> Ingest
    Ingest --> VectorDB
    UI --> LLM
    VectorDB --> UI
    VectorDB --> Logs
    LLM --> UI
    UI --> Logs
</div></code></pre>
<h2 id="3-key-modules-and-their-roles">3. Key Modules and Their Roles</h2>
<ul>
<li><strong>main.py</strong>: CLI entry point; orchestrates all backend operations.</li>
<li><strong>app.py</strong>: Streamlit web interface; mirrors CLI functionality with a modern UI.</li>
<li><strong>src/rag_pipeline.py</strong>: Core pipeline; manages ingestion, retrieval, and LLM calls.</li>
<li><strong>src/ingestion/document_loader.py</strong>: Loads and parses PDF, DOCX, TXT, and JSON files.</li>
<li><strong>src/utils/config_loader.py</strong>: Loads YAML config with dot-notation access.</li>
<li><strong>src/utils/init_manager.py</strong>: Initializes logging, loads .env, and sets up environment.</li>
<li><strong>src/utils/log_manager.py</strong>: Handles timestamped log file creation and management.</li>
</ul>
<h2 id="4-data-flow-and-processing-pipeline">4. Data Flow and Processing Pipeline</h2>
<pre><code class="language-mermaid"><div class="mermaid">sequenceDiagram
    participant U as User
    participant UI as Interface (Web/CLI)
    participant ING as Ingestion
    participant VDB as Vector DB
    participant LLM as LLM (GROQ)

    U->>UI: Submit document(s)
    UI->>ING: Load & parse
    ING->>VDB: Store embeddings
    U->>UI: Submit query
    UI->>VDB: Retrieve relevant chunks
    VDB-->>UI: Return chunks
    UI->>LLM: Send query + context
    LLM-->>UI: Generate answer
    UI-->>U: Show answer & sources
</div></code></pre>
<h2 id="5-security-and-configuration">5. Security and Configuration</h2>
<ul>
<li><strong>Secrets Management</strong>: All API keys (e.g., GROQ_API_KEY) are loaded from a <code>.env</code> file (see <code>.env.example</code>).</li>
<li><strong>Configuration</strong>: System behavior is controlled via <code>config/config.yaml</code> (logging, LLM, vector DB, etc.).</li>
<li><strong>Best Practices</strong>: <code>.env</code> is git-ignored; <code>.env.example</code> is provided for onboarding.</li>
</ul>
<h2 id="6-extensibility-and-customization">6. Extensibility and Customization</h2>
<pre><code class="language-mermaid"><div class="mermaid">flowchart LR
    subgraph Extensible Components
        A["Embeddings\n(HuggingFace, etc.)"]
        B["LLM Provider\n(GROQ, OpenAI, etc.)"]
        C["Document Loader\n(PDF, DOCX, TXT, JSON, ...)"]
        D["UI/UX\n(Streamlit, CLI, ...)"]
    end
    Config["config.yaml / .env"]
    Config --> A
    Config --> B
    Config --> C
    Config --> D
</div></code></pre>
<ul>
<li><strong>Pluggable Embeddings</strong>: Swap HuggingFace models via config.</li>
<li><strong>LLM Agnostic</strong>: Easily switch LLM providers by updating config and .env.</li>
<li><strong>Custom Ingestion</strong>: Extend <code>document_loader.py</code> for new file types.</li>
<li><strong>UI/UX</strong>: Add new Streamlit pages or CLI commands as needed.</li>
</ul>
<h2 id="7-cli-and-web-ui-design">7. CLI and Web UI Design</h2>
<ul>
<li><strong>CLI</strong>: Supports all operations (init, ingest, query, stats, clear, logs, etc.) with rich help and examples.</li>
<li><strong>Web UI</strong>: Streamlit app with dashboard, chat, ingestion, stats, and log management.</li>
<li><strong>Interactive Mode</strong>: CLI supports conversational Q&amp;A with <code>/stats</code>, <code>/help</code>, <code>/quit</code> commands.</li>
</ul>
<h2 id="8-logging-monitoring-and-testing">8. Logging, Monitoring, and Testing</h2>
<ul>
<li><strong>Logging</strong>: Timestamped log files per session; configurable via YAML.</li>
<li><strong>Monitoring</strong>: Real-time stats in both CLI and web UI.</li>
<li><strong>Testing</strong>: CLI commands for component and end-to-end tests; pytest integration.</li>
</ul>
<h2 id="9-supported-formats-and-deployment">9. Supported Formats and Deployment</h2>
<ul>
<li><strong>Documents</strong>: PDF, DOCX, TXT, JSON (extensible).</li>
<li><strong>Deployment</strong>: Cross-platform (Windows, Linux, Mac); web UI via Streamlit; CLI via Python.</li>
<li><strong>Hosting</strong>: See <code>docs/Streamlit_Hosting.md</code> for deployment options.</li>
</ul>
<h2 id="10-references-and-future-work">10. References and Future Work</h2>
<ul>
<li>
<p><strong>References</strong>:</p>
<ul>
<li>ChromaDB: https://www.trychroma.com/</li>
<li>LangChain: https://www.langchain.com/</li>
<li>GROQ: https://groq.com/</li>
<li>Streamlit: https://streamlit.io/</li>
</ul>
</li>
<li>
<p><strong>Future Work</strong>:</p>
<ul>
<li>Add support for more LLM providers (OpenAI, Azure, etc.)</li>
<li>Advanced analytics and visualization modules</li>
<li>Distributed/clustered vector store support</li>
<li>Enhanced security and RBAC for multi-user deployments</li>
<li>Automated document ingestion pipelines</li>
</ul>
</li>
</ul>
<hr>
<p><em>For implementation details, see the codebase and README. For deployment, see the Streamlit hosting guide in <code>docs/</code>.</em></p>

</body>
</html>
